# -*- coding: utf-8 -*-
"""Data Preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f8IZfXkYohGsahHkXwmoB_PI7xUWreby

# Data Preprocessing for Image Classification: Cats vs. Dogs

This notebook showcases an extensive workflow for advanced image preprocessing targeted at a binary classification challengeâ€”distinguishing between cats and dogs. Employing robust Python libraries such as OpenCV and PIL, this guide covers several critical preprocessing techniques. These methods are designed to optimize images for machine learning models, incorporating tasks such as noise addition, random cropping, color adjustments, and perspective transformations to enhance data robustness.

## Functions Overview

### 1. `load_images_to_binary`
Loads images from designated subfolders ('train' and 'test') and converts them into a compact binary format. This method is essential for handling large datasets efficiently, particularly in memory-constrained environments. It stores images in binary form along with labels ('cats' or 'dogs') and the dataset category ('train' or 'test').

**Parameters:**
- `base_dir`: The base directory containing the image datasets.
- `subfolder`: Specifies the subfolder ('train' or 'test') from which to load the images.

### 2. `to_grayscale`
Transforms color images to grayscale to simplify the data, beneficial for models that do not rely on color data for effective learning outcomes.

**Parameter:**
- `img_data`: The binary data of the image to convert.

### 3. `apply_median_filter`
Applies a median filter to smooth images by reducing noise. This filter is instrumental in minimizing unnecessary data variations that could affect model accuracy.

**Parameters:**
- `img_data`: The binary image data on which to apply the filter.
- `filter_size`: The dimension of the square filter mask used for the median filter.

### 4. `augment_image`
Enhances the dataset by introducing variability through random image transformations including rotation, shifting, and flipping. Such augmentations are crucial for training robust machine learning models capable of generalizing from varied data inputs.

**Parameter:**
- `img_data`: The binary image data to augment.

### 5. `add_noise`
Injects random noise into images, mimicking real-world imperfections and testing the model's resilience.

**Parameter:**
- `img_data`: The binary data of the image to add noise.

### 6. `random_crop`
Crops random sections of images to force the model to recognize features from partial views.

**Parameter:**
- `img_data`: The binary data of the image to crop randomly.

### 7. `color_jitter`
Randomly adjusts the brightness, contrast, and saturation to prepare the model for various lighting and color conditions.

**Parameter:**
- `img_data`: The binary data of the image for color adjustment.

### 8. `perspective_transformation`
Alters the image perspective, simulating different camera angles and orientations.

**Parameter:**
- `img_data`: The binary data of the image to transform the perspective.

## Execution and Visualization
The notebook applies each preprocessing function to a collection of images stored on Google Drive, showcasing the impact of each transformation through visual comparisons. These steps are illustrated with before-and-after images to highlight the effects of preprocessing techniques on enhancing data quality.

By completing this notebook, you will obtain a diverse and well-prepared dataset, optimized for training a machine learning model to accurately classify images as either cats or dogs.

# Why Use Binary Format?
- **Efficiency**: Binary formats are compact and efficient for storage and transmission because they represent the image data directly without any unnecessary overhead.
- **Speed**: Operations on binary data are generally faster than those on other data formats because they are closer to the hardware level.
- **Interoperability**: Binary data can be easily shared across different systems and software without compatibility issues, assuming the format is understood by the receiving system.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install keras

import os
import io
import cv2
from PIL import Image, ImageFilter, ImageEnhance
import numpy as np
import random
import matplotlib.pyplot as plt
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array
from tqdm import tqdm

base_dir = '/content/drive/MyDrive/Colab Notebooks/Computer Vision Toolbox/data/binaryclass/cats_dogs'

# Define global variables
IMAGE_SIZE = (150, 150)  # Define your desired image size
base_path = '/content/drive/MyDrive/Colab Notebooks/Computer Vision Toolbox/data/binaryclass/cats_dogs'
datasets = [os.path.join(base_path, 'train'), os.path.join(base_path, 'test')]
class_names = ['cats', 'dogs']  # Example class names
class_names_label = {name: i for i, name in enumerate(class_names)}

# Function to load images and labels for binary classification
def load_data(base_path, image_size=(150, 150)):
    """
    Load images from train and test directories, resize them, and return as training and testing datasets.
    This version is adapted for binary classification with labels in {0, 1}.

    Args:
        base_path (str): Path to the base directory containing 'train' and 'test' directories.
        image_size (tuple): Desired image size as (width, height).

    Returns:
        tuple: Tuple containing training and testing datasets:
               (images_train, labels_train, images_test, labels_test).
    """
    datasets = {'train': [], 'test': []}
    for phase in ['train', 'test']:
        data_path = os.path.join(base_path, phase)
        images = []
        labels = []
        print("Loading {} data...".format(phase))

        for folder in os.listdir(data_path):
            class_label = 1 if folder.lower() == 'dogs' else 0  # Assign 1 to 'dogs', 0 to 'cats'
            folder_path = os.path.join(data_path, folder)

            for file in tqdm(os.listdir(folder_path)):
                img_path = os.path.join(folder_path, file)
                image = cv2.imread(img_path)

                if image is not None:
                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                    image = cv2.resize(image, image_size)
                    image = image.astype(np.float32) / 255.0  # Normalize the images to [0, 1]

                    images.append(image)
                    labels.append(class_label)

        images = np.array(images, dtype='float32')
        labels = np.array(labels, dtype='int32')

        datasets[phase].append(images)
        datasets[phase].append(labels)

    return datasets['train'][0], datasets['train'][1], datasets['test'][0], datasets['test'][1]

images_train, labels_train, images_test, labels_test = load_data(base_path)

# Transformation functions

def to_grayscale(img_data):
    return cv2.cvtColor(img_data, cv2.COLOR_RGB2GRAY)

def apply_median_filter(img_data, filter_size=5):
    return cv2.medianBlur(img_data, filter_size)

def augment_image(img_data):
    datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )
    img_data = img_data.reshape((1,) + img_data.shape)  # Reshape to (1, height, width, channels)
    it = datagen.flow(img_data, batch_size=1)
    augmented_image = it.next()[0].astype('uint8')  # Retrieve augmented image and ensure data type
    return augmented_image

def add_noise(img_data):
    mean = 0
    var = 30
    sigma = var ** 0.5
    gauss = np.random.normal(mean, sigma, img_data.shape)
    gauss = gauss.reshape(img_data.shape)
    noisy_image = img_data + gauss
    noisy_image = np.clip(noisy_image, 0, 255).astype('uint8')  # Ensure pixel values are within valid range
    return noisy_image

def random_crop(img_data, crop_size=(100, 100)):
    height, width, _ = img_data.shape
    top = np.random.randint(0, height - crop_size[0])
    left = np.random.randint(0, width - crop_size[1])
    cropped_img = img_data[top:top + crop_size[0], left:left + crop_size[1]]
    cropped_img = cv2.resize(cropped_img, (width, height))  # Resize back to original dimensions
    return cropped_img

def color_jitter(img_data, alpha=1.5, beta=50):
    """ Apply brightness and contrast adjustments.
        alpha: contrast control (1.0-3.0)
        beta: brightness control (0-100)
    """
    new_image = np.zeros(img_data.shape, img_data.dtype)
    # Adjustment for each pixel
    for y in range(img_data.shape[0]):
        for x in range(img_data.shape[1]):
            for c in range(img_data.shape[2]):
                new_image[y,x,c] = np.clip(alpha*img_data[y,x,c] + beta, 0, 255)
    return new_image

def perspective_transformation(img_data):
    rows, cols, ch = img_data.shape
    src_points = np.float32([[0, 0], [cols-1, 0], [0, rows-1], [cols-1, rows-1]])
    dst_points = src_points + np.random.uniform(-20, 20, src_points.shape).astype(np.float32)
    matrix = cv2.getPerspectiveTransform(src_points, dst_points)
    img_transformed = cv2.warpPerspective(img_data, matrix, (cols, rows))
    return img_transformed



